{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenProjection 1.0\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## Contents:\n",
    "1. [Intro](#1-intro): What is OpenProjection?\n",
    "\n",
    "2. [Context](#2-context): Can be subjective experience be studied quantitatively?\n",
    "\n",
    "3. [Data](#3-data)\n",
    "    1. [Load and explore data](#31-load-and-explore-data)\n",
    "    \n",
    "    2. [Extract features and targets](#33-extract-features-and-targets)\n",
    "        1. [Features](#331-features)\n",
    "\n",
    "        2. [Targets](#322-targets)\n",
    "            \n",
    "            1. [Categorical (for classification)](#3221-categorical)\n",
    "\n",
    "            1. [Continuous (for regression)](#3222-continous)\n",
    "            \n",
    "                1. [Unsupervised target selction](#32221-unsupervised-target-selection) \n",
    "\n",
    "4. [Pipelines](#4-pipelines)\n",
    "    1. [Classification](#41-classification)\n",
    "    \n",
    "    2. [Regression](#42-regression)\n",
    "\n",
    "5. [Conclusion](#5-conclusion)\n",
    "\n",
    "## **1. Intro:**\n",
    "OpenProjection is a basic open-source machine learning project I designed during my master's. Its main use is as a very beginner-friendly, step-by-step tutorial for machine learning in Python. It covers different types of supervised learning problems, including both regression and classification, as well as an embedded unsupervised learning problem. The nature of the data used herein also means we'll be touching on aspects of Natural Language Processing (NLP), but won't go into excessive detail. We'll also practice using an API (remotely accessing some website's functions).\n",
    "\n",
    "The entire thing can be run from start to finish in Google Colab [here](), with an accopmanying video walkthrough [here](). On the other hand, the entire script is also available if you wanna just jump right in. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## **2. Context:** \n",
    "It is said that we do not perceive the world as it is, but as we are. Such poetic truisms capture a key phenomenon that the fields of philosophy, psychology and neurosicence have been grappling with for millenia, centuries and decades, respectively: individuals experience themselves and the world in their own unique and rather impenetrable way. Getting to the core subjective experience holds great promise for many other herculean tasks, such as understanding, preventing and treating the distorsions of subjective experience that lead to mental health diagnoses and ultimately, revealing the nature of consciousness itself. Obviously, we won't be solving the Hard Problem in this notebook, but we will attempt a first pass at quantifying verbal reports of subjective experience and relating them to mental health (broadly construed).\n",
    "\n",
    "We'll be working with a classic test in psychology, the Thematic Apperception Test (TAT), designed to assess variations in how individuals interpret ambiguous situations. Following from the popular adage at the beginnning of this section, the TAT is founded on the idea that people reveal aspects of themselves when confronted with non-obvious situations. However, the degree to which this is true has never truly been exposed to quantitative statistical verification....until now. \n",
    "\n",
    "In simple terms, our goal is to turn TAT verbal reports into numeric variables and determine if they hold any significance/possess any predictive power. So, we'll first need some kind of algorithm that turns words into numbers, and we'll also need some target to predict which would validate whether our algorithm is useful or not. \n",
    "<br>\n",
    "\n",
    "## **3. Data:**\n",
    "Now we're ready to get our hands dirty, so to speak. Open TAT data has been graciously and freely provided by Middle Tennessee State Univeristy [here](https://jewlscholar.mtsu.edu/items/a54a5d18-3cfa-4700-bbf5-7d68a4375df3). To many, this step is the most crucial since machine learning does not learn out of thin air. The quality of our models depends on the quality of our training data. Or, more bluntly, \"gargabe in, garbage out\". \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### **3.1. Load and explore data**\n",
    "When taking a first look at fresh data, you'll want to know a couple of important things:\n",
    "* How many rows (observations) \n",
    "* How many columns (variables), and what kind of data they contain\n",
    "* If there are any missing values, as well as **how many** and **in which columns** they are if so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### Load data into dataframe\n",
    "df = pd.read_excel('TAT Narrative Collection.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID #</th>\n",
       "      <th>Source/ Permission Statement</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Date of Admin</th>\n",
       "      <th>Card #</th>\n",
       "      <th>Psychiatric Diagnosis (If Any)</th>\n",
       "      <th>Circumstances surrounding Test (clinical, timed, not timed, experiental)</th>\n",
       "      <th>Other</th>\n",
       "      <th>Narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Used with permission of the Magda Arnold estat...</td>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Prior to 1962</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"inverterate truant\"</td>\n",
       "      <td>Well, this boy is looking at his violin and tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Used with permission of the Magda Arnold estat...</td>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Prior to 1962</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"inverterate truant\"</td>\n",
       "      <td>This girl is going to school because her mothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Used with permission of the Magda Arnold estat...</td>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Prior to 1962</td>\n",
       "      <td>3BM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"inverterate truant\"</td>\n",
       "      <td>This boy is crying ‘cause his mother made him ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Used with permission of the Magda Arnold estat...</td>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Prior to 1962</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"inverterate truant\"</td>\n",
       "      <td>Oh, that looks like this guy is pretty angry. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Used with permission of the Magda Arnold estat...</td>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Prior to 1962</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"inverterate truant\"</td>\n",
       "      <td>Oh, that seems like this woman is watching to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID #                       Source/ Permission Statement Age   Sex  \\\n",
       "0            1  Used with permission of the Magda Arnold estat...  15  male   \n",
       "1            1  Used with permission of the Magda Arnold estat...  15  male   \n",
       "2            1  Used with permission of the Magda Arnold estat...  15  male   \n",
       "3            1  Used with permission of the Magda Arnold estat...  15  male   \n",
       "4            1  Used with permission of the Magda Arnold estat...  15  male   \n",
       "\n",
       "      Race  Date of Admin Card # Psychiatric Diagnosis (If Any)  \\\n",
       "0  unknown  Prior to 1962      1                            NaN   \n",
       "1  unknown  Prior to 1962      2                            NaN   \n",
       "2  unknown  Prior to 1962    3BM                            NaN   \n",
       "3  unknown  Prior to 1962      4                            NaN   \n",
       "4  unknown  Prior to 1962      5                            NaN   \n",
       "\n",
       "  Circumstances surrounding Test (clinical, timed, not timed, experiental)  \\\n",
       "0                                                NaN                         \n",
       "1                                                NaN                         \n",
       "2                                                NaN                         \n",
       "3                                                NaN                         \n",
       "4                                                NaN                         \n",
       "\n",
       "                   Other                                          Narrative  \n",
       "0  \"inverterate truant\"   Well, this boy is looking at his violin and tr...  \n",
       "1  \"inverterate truant\"   This girl is going to school because her mothe...  \n",
       "2  \"inverterate truant\"   This boy is crying ‘cause his mother made him ...  \n",
       "3  \"inverterate truant\"   Oh, that looks like this guy is pretty angry. ...  \n",
       "4  \"inverterate truant\"   Oh, that seems like this woman is watching to ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Show first five entries\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### How many observations\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### How many columns\n",
    "len(df.columns)\n",
    "\n",
    "### Here, df.columns is a list of column names, try it out:\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Numbers of rows and columns, respectively\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject ID #                                                                object\n",
       "Source/ Permission Statement                                                object\n",
       "Age                                                                         object\n",
       "Sex                                                                         object\n",
       "Race                                                                        object\n",
       "Date of Admin                                                               object\n",
       "Card #                                                                      object\n",
       "Psychiatric Diagnosis (If Any)                                              object\n",
       "Circumstances surrounding Test (clinical, timed, not timed, experiental)    object\n",
       "Other                                                                       object\n",
       "Narrative                                                                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get datatypes for each column, this will also show us the column names\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check if there are NaN or null values in the dataframe\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject ID #                                                                  0\n",
       "Source/ Permission Statement                                                  0\n",
       "Age                                                                           0\n",
       "Sex                                                                           0\n",
       "Race                                                                          0\n",
       "Date of Admin                                                                 0\n",
       "Card #                                                                        0\n",
       "Psychiatric Diagnosis (If Any)                                              483\n",
       "Circumstances surrounding Test (clinical, timed, not timed, experiental)    418\n",
       "Other                                                                       548\n",
       "Narrative                                                                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Since there are NaNs, let's see how many per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schizophrenia                                                        40\n",
       "psychoneurosis                                                       28\n",
       "personality disorder                                                 20\n",
       "Psychoneurosis: Somatization                                         20\n",
       "schizophrenia, paranoid type, in remission                           20\n",
       "deteriorated organic from syphilis of the central nervious system    20\n",
       "\"Severe problems in the sexual area\"                                 20\n",
       "behavior disorder                                                    11\n",
       "accute symptoms; inability to stay awake                              1\n",
       "?                                                                     1\n",
       "Name: Psychiatric Diagnosis (If Any), dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The 'Psychiatric Diagnosis' column caught my attention, let's see what's in there\n",
    "### This is *foreshadowing* for the classification problem later on\n",
    "\n",
    "df['Psychiatric Diagnosis (If Any)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject described as a scholastic in a teaching order                                                                       20\n",
       "Wants to break free of relationships and become independent                                                                 20\n",
       " \"quite delusional and incoherent, but cooperative during the examination and in the ward\"                                  20\n",
       "\"Problems so intense that they threaten his capacity to control his drives, allay his anxiety, and alleviate his guilt.\"    20\n",
       "Executive Development Program participant                                                                                   10\n",
       "\"inverterate truant\"                                                                                                         5\n",
       "Young woman whose mother divorced and remarried                                                                              4\n",
       "\"Poor teacher\"                                                                                                               3\n",
       "Teacher considered inadequate by her pupils                                                                                  3\n",
       "interested in the physical world and science in general                                                                      3\n",
       "Good teacher                                                                                                                 2\n",
       "\"low achiever\"                                                                                                               2\n",
       "\"high achiever\"                                                                                                              2\n",
       "\"High Achiever\"                                                                                                              1\n",
       "young woman whose mother divorced and remarried                                                                              1\n",
       "Name: Other, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The contents of the 'other' column are also intriguing, let's see how many unique values\n",
    "df['Other'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401681d204de403ca5c63890a77dd53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='report', max=663), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.view(report)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For fun, let's create a slider to scroll through verbal reports\n",
    "### This is a good way to get a sense of the data\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "### Create a slider\n",
    "slider = widgets.IntSlider(min=0, \n",
    "                           max=len(df)-1, \n",
    "                           step=1)\n",
    "\n",
    "### Link slider to dataframe\n",
    "def view(report):\n",
    "    \"\"\"\n",
    "    Displays narratives in Markdown format.\n",
    "    \n",
    "    Args:\n",
    "        report (str): Slider controlling the narrative to display by index.\n",
    "    \"\"\"\n",
    "    narrative = df['Narrative'][report]\n",
    "    display(Markdown(narrative))\n",
    "\n",
    "widgets.interact(view, report=slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2. Extract features and targets**\n",
    "#### **3.2.1 Features**\n",
    "Now we'll use the OpenAI API to extract numerical representations of the narratives.\n",
    "\n",
    "This is the first step in the pipeline and requires you to have an OpenAI account (and a credit card) to genereate an API key. Embeddings are ridiculously cheap,costing a fraction of a fraction of a penny for many thousands of tokens.\n",
    "If you choose to do so, you'll simply need to replace the API key below with your own.\n",
    "\n",
    "However, if you can't or don't want to create an account, embeddings are free to share and \n",
    "can be accessed from the repo: ['https://raw.githubusercontent.com/username/repository-name/master/csv_file1.csv']. \n",
    "If you choose to do so, you can skip to the next cell and load the embeddings directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# openai.api_key = \"your-api-key-here\"\n",
    "\n",
    "### Function to get embeddings, do not run this neeedlessly as it will cost you money. \n",
    "### Ideally, its \"one and done\", so always test on a small sample before running on the full dataset.\n",
    "# def get_embedding(text: str, model=\"text-embedding-ada-002\") -> list[float]:\n",
    "#    return openai.Embedding.create(input=[text], model=model)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "### Create embeddings for each narrative\n",
    "# embeddings = [get_embedding(i) for i in clean_df.Narrative]\n",
    "\n",
    "### Load embeddgins to dataframe with customized column names\n",
    "# clean_df = pd.DataFrame(embeddings, columns=[\"Col\" + str(i) for i in range(len(embeddings)))\n",
    "\n",
    "### Save dataframe to csv. Remember, we don't want to do this again. \n",
    "# clean_df.to_csv(\"TAT_Embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dataframe from csv (if you downloaded it from the repo)\n",
    "# embeddings = pd.read_csv('Path to csv file/TAT_Embeddings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.2. Targets**\n",
    "##### **3.2.2.1. Categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We now have half of the data we need to train a model: the embeddings, or features (X).\n",
    "### The other half will be the target we're either trying to predict or classify (y).\n",
    "\n",
    "### The distinction here is whether the target is a continuous variable (fit for prediction)\n",
    "### or a categorical one (fit for classification).\n",
    "\n",
    "### Since we'll demonstrate both, we'll create two targets: \n",
    "### 1- Psychiatric Diagnosis (Classifcation)\n",
    "### 2- Psycholinguistic dimension scores (Prediction)\n",
    "\n",
    "### First, we'll create the classification target.\n",
    "### We'll use the 'Psychiatric Diagnosis' column, but we'll need to convert it to a numerical format.\n",
    "### For the sake of simplicity, we'll consider only two classes:\n",
    "### schizophrenia and psychoneurosis (combined from two classes)\n",
    "\n",
    "# Create df whith only the rows that contain 'schizophrenia' as a diagnosis\n",
    "schiz = df[df['Psychiatric Diagnosis (If Any)'] == 'schizophrenia']\n",
    "\n",
    "# Create df whith only the rows that contain 'psychoneurosis' as a diagnosis, including those with 'Psychoneurosis : Somatization'\n",
    "psychoneuro = df[(df['Psychiatric Diagnosis (If Any)'] == 'Psychoneurosis: Somatization') | (df['Psychiatric Diagnosis (If Any)'] == 'psychoneurosis')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 11)\n",
      "(48, 11)\n"
     ]
    }
   ],
   "source": [
    "### Now we have two roughly equivalent categiries to predict\n",
    "print(schiz.shape)\n",
    "print(psychoneuro.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.2.2.2 Continous**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To create our regression targets, I decided to use psycholinguistic dimensions\n",
    "### inspired by those produced by the Linguistic Inquiry and Word Count (LIWC-22) software.\n",
    "### Since this software is only for academic use and cannot be redistributed, I have simulated\n",
    "### the dimensions and provide them freely to you here: ['https://raw.githubusercontent.com/username/repository-name/master/csv_file1.csv']\n",
    "targets = pd.read_csv(\"\"\"insert path to csv here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.2.2.2.1 Unsupervised target selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Pipelines:**\n",
    "### **4.1. Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_append(X, y):\n",
    "    \"\"\"type(int)-encodes targets, then appends it to the X\"\"\"\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = pd.Series(le.fit_transform(y), name=y.name)\n",
    "    return pd.concat([X.reset_index(), y_encoded.reset_index()], axis=1).drop('index', axis=1)\n",
    "\n",
    "class ClassifierPipeline:\n",
    "    def __init__(self, data, target_col, test_size=0.3):\n",
    "        self.data = data\n",
    "        self.target_col = target_col\n",
    "        self.test_size = test_size\n",
    "        self.models = {}\n",
    "\n",
    "    def split_data(self):\n",
    "        X = self.data.drop(columns=[self.target_col])\n",
    "        y = pd.Categorical(self.data[self.target_col])\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=self.test_size)\n",
    "        \n",
    "    def scale_fit_svm(self):\n",
    "        pipe = Pipeline(steps = [('scaler', StandardScaler()), \n",
    "                                 ('svm', LogisticRegression())])\n",
    "        pipe.fit(self.X_train, self.y_train)\n",
    "        self.models[f'lr_{self.target_col}'] = pipe\n",
    "\n",
    "    def evaluate(self, show=False):\n",
    "        for name, model in self.models.items():\n",
    "            y_pred = model.predict(self.X_test)\n",
    "\n",
    "            accuracy = accuracy_score(self.y_test, y_pred)\n",
    "            conf_matrix = confusion_matrix(self.y_test, y_pred)\n",
    "            precision = precision_score(self.y_test, y_pred, average='macro', zero_division=0)\n",
    "            recall = recall_score(self.y_test, y_pred, average='macro', zero_division=0)\n",
    "            f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "            class_rep = classification_report(self.y_test, y_pred, zero_division=0)\n",
    "\n",
    "            self.models[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'confusion_matric': conf_matrix,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'class_rep': class_rep\n",
    "            }\n",
    "            \n",
    "            if show == True:\n",
    "                #print(f\"{name} Classification report: {class_rep}\")\n",
    "                print(f\"{name} accuracy: {accuracy:.3f}\")\n",
    "                print(f\"{name} precision: {precision:.3f}\")\n",
    "                print(f\"{name} recall: {recall:.3f}\")\n",
    "                print(f\"{name} f1: {f1:.3f}\")\n",
    "            \n",
    "    def average_scores(self):\n",
    "        scores = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "        for name, model in self.models.items():\n",
    "            scores['accuracy'].append(model['accuracy'])\n",
    "            scores['precision'].append(model['precision'])\n",
    "            scores['recall'].append(model['recall'])\n",
    "            scores['f1'].append(model['f1'])\n",
    "\n",
    "        avg_scores = {k: sum(v) / len(v) for k, v in scores.items()}\n",
    "        return avg_scores\n",
    "            \n",
    "def rankings_all_targets(targets):\n",
    "    for target in targets: \n",
    "        pipeline = ClassifierPipeline(encode_append(lens_cards_all_ada, psych_df[target]), target)\n",
    "        pipeline.split_data()\n",
    "        pipeline.scale_fit_svm()\n",
    "        pipeline.evaluate()\n",
    "        scores = pipeline.average_scores()\n",
    "    return scores\n",
    "\n",
    "rankings_all_targets(psych_df.iloc[:,6:].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2. Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def append(X, y):\n",
    "#     return pd.concat([X.reset_index(), y.reset_index()], axis=1).drop('index', axis=1)\n",
    "\n",
    "def scale_fit(X, y):\n",
    "    model = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()), \n",
    "            ('regressor', LinearRegression())\n",
    "        ])\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "        \n",
    "class RegressionPipeline:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.X = self.data.iloc[:,:-1]\n",
    "        self.y = self.data.iloc[:,-1]\n",
    "          \n",
    "    def evaluate(self):\n",
    "        loo = LeaveOneOut()\n",
    "        y_pred = []\n",
    "        y_test_all = []\n",
    "        for train_index, test_index in loo.split(self.X):\n",
    "            X_train, X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
    "            y_train, y_test = self.y.iloc[train_index], self.y.iloc[test_index]\n",
    "            model = scale_fit(X_train, y_train)\n",
    "            y_pred.append(model.predict(X_test)[0])\n",
    "            y_test_all.append(y_test.values[0])\n",
    "\n",
    "        mse = mean_squared_error(y_test_all, y_pred)\n",
    "        r2 = r2_score(y_test_all, y_pred)\n",
    "        corr = np.corrcoef(y_pred, y_test_all)[0,1]\n",
    "        #f_values, p_values = f_regression(y_pred, y_test_all)\n",
    "        return mse, r2, corr\n",
    "            \n",
    "def rankings_all_targets(targets):\n",
    "    for target in targets: \n",
    "        pipeline = RegressionPipeline(append(lens_cards_all, targets_df[target][::-1]))                           \n",
    "        mse, r2, corr = pipeline.evaluate()\n",
    "        print(f\"{target} - MSE: {mse:.3f}, R2: {r2:.3f}, Correlation: {corr:.3f}\")\n",
    "\n",
    "rankings_all_targets(targets_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Conclusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift6501",
   "language": "python",
   "name": "ift6501"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
